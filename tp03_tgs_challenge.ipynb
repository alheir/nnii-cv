{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10151,"databundleVersionId":59042,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"ITBA - Ingeniería Electrónica\n\n25.87 - Redes Neuronales II - Computer Vision\n\n---\n\n**TP3 - TGS - Nov. 2024**\n\nGrupo: \n* HEIR, Alejandro Nahuel - 62496\n* SBRUZZI, Juan Francisco - 62517\n\n---\n\nChallenge: [TGS Salt Identification Challenge](https://www.kaggle.com/competitions/tgs-salt-identification-challenge)\n\nReferencia: [U-net, dropout, augmentation, stratification](https://www.kaggle.com/code/phoenigs/u-net-dropout-augmentation-stratification)\n\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom keras.preprocessing.image import load_img\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, BatchNormalization, LeakyReLU\n\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.278376Z","iopub.execute_input":"2024-11-15T20:24:34.279030Z","iopub.status.idle":"2024-11-15T20:24:34.286771Z","shell.execute_reply.started":"2024-11-15T20:24:34.278988Z","shell.execute_reply":"2024-11-15T20:24:34.285772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/tgs-salt-identification-challenge/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"/kaggle/input/tgs-salt-identification-challenge/depths.csv\", index_col='id')","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.288572Z","iopub.execute_input":"2024-11-15T20:24:34.289127Z","iopub.status.idle":"2024-11-15T20:24:34.371940Z","shell.execute_reply.started":"2024-11-15T20:24:34.289083Z","shell.execute_reply":"2024-11-15T20:24:34.371082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_df.shape, depths_df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.373360Z","iopub.execute_input":"2024-11-15T20:24:34.373662Z","iopub.status.idle":"2024-11-15T20:24:34.378701Z","shell.execute_reply.started":"2024-11-15T20:24:34.373631Z","shell.execute_reply":"2024-11-15T20:24:34.377759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.379887Z","iopub.execute_input":"2024-11-15T20:24:34.380194Z","iopub.status.idle":"2024-11-15T20:24:34.397337Z","shell.execute_reply.started":"2024-11-15T20:24:34.380154Z","shell.execute_reply":"2024-11-15T20:24:34.396316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"depths_df","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.399359Z","iopub.execute_input":"2024-11-15T20:24:34.399969Z","iopub.status.idle":"2024-11-15T20:24:34.410170Z","shell.execute_reply.started":"2024-11-15T20:24:34.399933Z","shell.execute_reply":"2024-11-15T20:24:34.409251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"depths_df['z']","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.411374Z","iopub.execute_input":"2024-11-15T20:24:34.412102Z","iopub.status.idle":"2024-11-15T20:24:34.422708Z","shell.execute_reply.started":"2024-11-15T20:24:34.412069Z","shell.execute_reply":"2024-11-15T20:24:34.421892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train_df.join(depths_df) # agrega depths a cada id de train\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.423979Z","iopub.execute_input":"2024-11-15T20:24:34.424463Z","iopub.status.idle":"2024-11-15T20:24:34.443901Z","shell.execute_reply.started":"2024-11-15T20:24:34.424416Z","shell.execute_reply":"2024-11-15T20:24:34.443008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = depths_df[~depths_df.index.isin(train_df.index)] # test como los depths que no son train\ntest_df","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.445175Z","iopub.execute_input":"2024-11-15T20:24:34.445900Z","iopub.status.idle":"2024-11-15T20:24:34.462037Z","shell.execute_reply.started":"2024-11-15T20:24:34.445851Z","shell.execute_reply":"2024-11-15T20:24:34.461094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -o -q -u \"/kaggle/input/tgs-salt-identification-challenge/train.zip\" -d \"/kaggle/input/train/\"\n!unzip -o -q -u \"/kaggle/input/tgs-salt-identification-challenge/test.zip\" -d \"/kaggle/input/test/\"","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:34.463375Z","iopub.execute_input":"2024-11-15T20:24:34.464033Z","iopub.status.idle":"2024-11-15T20:24:42.387466Z","shell.execute_reply.started":"2024-11-15T20:24:34.463984Z","shell.execute_reply":"2024-11-15T20:24:42.386126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tree -d","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:42.389071Z","iopub.execute_input":"2024-11-15T20:24:42.389424Z","iopub.status.idle":"2024-11-15T20:24:43.489976Z","shell.execute_reply.started":"2024-11-15T20:24:42.389386Z","shell.execute_reply":"2024-11-15T20:24:43.488807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -1 /kaggle/input/test/images/ | wc -l\n!ls -1 /kaggle/input/train/images/ | wc -l\n!ls -1 /kaggle/input/train/masks/ | wc -l","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:43.495120Z","iopub.execute_input":"2024-11-15T20:24:43.495584Z","iopub.status.idle":"2024-11-15T20:24:46.703826Z","shell.execute_reply.started":"2024-11-15T20:24:43.495539Z","shell.execute_reply":"2024-11-15T20:24:46.702694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# se agregan las imágenes al train_df, normalizadas y BW\ntrain_df['images'] = [np.array(load_img(\"/kaggle/input/train/images/{}.png\".format(idx), color_mode='grayscale')) / 255 for idx in tqdm(train_df.index)]","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:46.705300Z","iopub.execute_input":"2024-11-15T20:24:46.705649Z","iopub.status.idle":"2024-11-15T20:24:49.062688Z","shell.execute_reply.started":"2024-11-15T20:24:46.705613Z","shell.execute_reply":"2024-11-15T20:24:49.061743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# se agregan las masks al train_df\ntrain_df['masks'] = [np.array(load_img(\"/kaggle/input/train/masks/{}.png\".format(idx), color_mode='grayscale')) for idx in tqdm(train_df.index)]\ntrain_df['masks'] = train_df['masks'].apply(lambda x: (x > 0).astype(np.uint8))","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:49.064111Z","iopub.execute_input":"2024-11-15T20:24:49.064615Z","iopub.status.idle":"2024-11-15T20:24:49.902389Z","shell.execute_reply.started":"2024-11-15T20:24:49.064569Z","shell.execute_reply":"2024-11-15T20:24:49.901598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(50)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:24:49.903503Z","iopub.execute_input":"2024-11-15T20:24:49.903791Z","iopub.status.idle":"2024-11-15T20:25:01.653893Z","shell.execute_reply.started":"2024-11-15T20:24:49.903761Z","shell.execute_reply":"2024-11-15T20:25:01.652899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Las masks son las anotaciones de cada pixel de las imagenes:\n* 1: sal\n* 0: sedimento","metadata":{}},{"cell_type":"code","source":"for i in range(1, 7):\n    refid = train_df.sample(1).index[0] # id random del train_df\n    print(f\"Para id={refid}, z={train_df['z'][refid]}\")\n\n    fig, ax = plt.subplots(1, 2, figsize=(4, 4))\n\n    ax[0].imshow(train_df['images'][refid], cmap='gray')\n    ax[0].set_title(f\"image {refid}\")\n\n    ax[1].imshow(train_df['masks'][refid], cmap='gray')\n    ax[1].set_title(f\"mask {refid}\")\n    plt.show()\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:01.655115Z","iopub.execute_input":"2024-11-15T20:25:01.655527Z","iopub.status.idle":"2024-11-15T20:25:03.795401Z","shell.execute_reply.started":"2024-11-15T20:25:01.655489Z","shell.execute_reply":"2024-11-15T20:25:03.794494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size_ori = 101 # 101x101\nimg_size_target = 128 # 128x128\n\ndef upsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n    #res[:img_size_ori, :img_size_ori] = img\n    #return res\n    \ndef downsample(img):\n    if img_size_ori == img_size_target:\n        return img\n    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n    #return img[:img_size_ori, :img_size_ori]","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:03.796642Z","iopub.execute_input":"2024-11-15T20:25:03.796974Z","iopub.status.idle":"2024-11-15T20:25:03.803082Z","shell.execute_reply.started":"2024-11-15T20:25:03.796922Z","shell.execute_reply":"2024-11-15T20:25:03.802092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Salt coverage classification","metadata":{}},{"cell_type":"code","source":"train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\ntrain_df.coverage = train_df.coverage / np.max(train_df.coverage) \n\nmin_cov = np.floor(np.min(train_df.coverage)).astype(np.float64)\nmax_cov = np.ceil(np.max(train_df.coverage)).astype(np.float64)\n\nmin_cov, max_cov","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:03.804213Z","iopub.execute_input":"2024-11-15T20:25:03.804552Z","iopub.status.idle":"2024-11-15T20:25:03.906721Z","shell.execute_reply.started":"2024-11-15T20:25:03.804520Z","shell.execute_reply":"2024-11-15T20:25:03.905863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cov_to_class(val, num_classes=11):    \n#     if val < min_cov or val > max_cov:\n#         raise ValueError(f\"Coverage value ({val}) is outside the expected range ({min_cov} - {max_cov})\")\n\n#     normalized_cov = (val - min_cov) / (max_cov - min_cov)\n\n#     class_index = int(np.floor(normalized_cov * num_classes))\n#     return class_index\n    for i in range(0, num_classes):\n        if val * 10 <= i :\n            return i\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:03.907948Z","iopub.execute_input":"2024-11-15T20:25:03.908343Z","iopub.status.idle":"2024-11-15T20:25:03.919867Z","shell.execute_reply.started":"2024-11-15T20:25:03.908307Z","shell.execute_reply":"2024-11-15T20:25:03.918887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(8,3))\nplt.suptitle(\"Salt coverage\")\naxs[0].hist(train_df.coverage, bins=20)\naxs[0].set_xlabel(\"Coverage\")\naxs[1].hist(train_df.coverage_class, bins=11)\naxs[1].set_xlabel(\"Coverage class\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:03.920971Z","iopub.execute_input":"2024-11-15T20:25:03.921303Z","iopub.status.idle":"2024-11-15T20:25:04.373599Z","shell.execute_reply.started":"2024-11-15T20:25:03.921258Z","shell.execute_reply":"2024-11-15T20:25:04.372625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(train_df.coverage, train_df.coverage_class)\nplt.xlabel(\"Coverage\")\nplt.ylabel(\"Coverage class\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:04.374931Z","iopub.execute_input":"2024-11-15T20:25:04.375340Z","iopub.status.idle":"2024-11-15T20:25:04.947055Z","shell.execute_reply.started":"2024-11-15T20:25:04.375295Z","shell.execute_reply":"2024-11-15T20:25:04.946045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Depth distributions","metadata":{}},{"cell_type":"code","source":"plt.hist(train_df.z, label=\"Train\", alpha=0.25, density=True, bins=25)\nplt.hist(test_df.z, label=\"Test\", alpha=0.25, density=True, bins=25)\nplt.legend()\nplt.title(\"Depth distribution\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:04.948426Z","iopub.execute_input":"2024-11-15T20:25:04.948732Z","iopub.status.idle":"2024-11-15T20:25:05.337107Z","shell.execute_reply.started":"2024-11-15T20:25:04.948700Z","shell.execute_reply":"2024-11-15T20:25:05.336168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some example images","metadata":{}},{"cell_type":"code","source":"max_images = 60\ngrid_width = 15\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height, grid_width, figsize=(grid_width, grid_height))\nfor i, idx in enumerate(train_df.index[:max_images]):\n    img = train_df.loc[idx].images\n    mask = train_df.loc[idx].masks\n    ax = axs[int(i / grid_width), i % grid_width]\n    ax.imshow(img, cmap=\"Greys\")\n    ax.imshow(mask, alpha=0.3, cmap=\"Greens\")\n    ax.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n    ax.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n    ax.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\nplt.suptitle(\"Green: salt. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:05.338758Z","iopub.execute_input":"2024-11-15T20:25:05.339744Z","iopub.status.idle":"2024-11-15T20:25:11.713099Z","shell.execute_reply.started":"2024-11-15T20:25:05.339696Z","shell.execute_reply":"2024-11-15T20:25:11.712116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train/validation split w/ stratification by salt coverage","metadata":{}},{"cell_type":"code","source":"ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state=1337)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:11.714406Z","iopub.execute_input":"2024-11-15T20:25:11.714757Z","iopub.status.idle":"2024-11-15T20:25:19.347018Z","shell.execute_reply.started":"2024-11-15T20:25:11.714716Z","shell.execute_reply":"2024-11-15T20:25:19.346203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_img = np.zeros((img_size_target, img_size_target), dtype=train_df.images.loc[ids_train[10]].dtype)\ntmp_img[:img_size_ori, :img_size_ori] = train_df.images.loc[ids_train[10]]\nfix, axs = plt.subplots(1, 2, figsize=(15,5))\naxs[0].imshow(tmp_img, cmap=\"Greys\")\naxs[0].set_title(\"Original image\")\naxs[1].imshow(x_train[10].squeeze(), cmap=\"Greys\")\naxs[1].set_title(\"Scaled image\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:19.348256Z","iopub.execute_input":"2024-11-15T20:25:19.348621Z","iopub.status.idle":"2024-11-15T20:25:19.907148Z","shell.execute_reply.started":"2024-11-15T20:25:19.348583Z","shell.execute_reply":"2024-11-15T20:25:19.906223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data augmentation\n\n> En la implementación de referencia, solo hacen mirror vertical","metadata":{}},{"cell_type":"code","source":"x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\ny_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:19.908455Z","iopub.execute_input":"2024-11-15T20:25:19.908906Z","iopub.status.idle":"2024-11-15T20:25:20.783583Z","shell.execute_reply.started":"2024-11-15T20:25:19.908857Z","shell.execute_reply":"2024-11-15T20:25:20.782494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 10, figsize=(15,3))\nfor i in range(10):\n    axs[0][i].imshow(x_train[i].squeeze(), cmap=\"Greys\")\n    axs[0][i].imshow(y_train[i].squeeze(), cmap=\"Greens\", alpha=0.3)\n    axs[1][i].imshow(x_train[int(len(x_train)/2 + i)].squeeze(), cmap=\"Greys\")\n    axs[1][i].imshow(y_train[int(len(y_train)/2 + i)].squeeze(), cmap=\"Greens\", alpha=0.3)\nfig.suptitle(\"Top row: original images, bottom row: augmented images\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:20.784918Z","iopub.execute_input":"2024-11-15T20:25:20.785222Z","iopub.status.idle":"2024-11-15T20:25:23.395174Z","shell.execute_reply.started":"2024-11-15T20:25:20.785191Z","shell.execute_reply":"2024-11-15T20:25:23.394278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model, U-Net","metadata":{}},{"cell_type":"code","source":"# def build_model(input_layer, start_neurons):\n#     # 128 -> 64\n#     conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(input_layer)\n#     conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n#     pool1 = MaxPooling2D((2, 2))(conv1)\n#     pool1 = Dropout(0.25)(pool1)\n\n#     # 64 -> 32\n#     conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n#     conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n#     pool2 = MaxPooling2D((2, 2))(conv2)\n#     pool2 = Dropout(0.5)(pool2)\n\n#     # 32 -> 16\n#     conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n#     conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n#     pool3 = MaxPooling2D((2, 2))(conv3)\n#     pool3 = Dropout(0.5)(pool3)\n\n#     # 16 -> 8\n#     conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n#     conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n#     pool4 = MaxPooling2D((2, 2))(conv4)\n#     pool4 = Dropout(0.5)(pool4)\n\n#     # Middle\n#     convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n#     convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(convm)\n\n#     # 8 -> 16\n#     deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n#     uconv4 = concatenate([deconv4, conv4])\n#     uconv4 = Dropout(0.5)(uconv4)\n#     uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n#     uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n\n#     # 16 -> 32\n#     deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n#     uconv3 = concatenate([deconv3, conv3])\n#     uconv3 = Dropout(0.5)(uconv3)\n#     uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n#     uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n\n#     # 32 -> 64\n#     deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n#     uconv2 = concatenate([deconv2, conv2])\n#     uconv2 = Dropout(0.5)(uconv2)\n#     uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n#     uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n\n#     # 64 -> 128\n#     deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n#     uconv1 = concatenate([deconv1, conv1])\n#     uconv1 = Dropout(0.5)(uconv1)\n#     uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n#     uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n\n#     uconv1 = Dropout(0.5)(uconv1)\n#     output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n#     return output_layer\n\n# input_layer = Input((img_size_target, img_size_target, 1))\n# output_layer = build_model(input_layer, 16)\n\ndef build_model(input_layer, start_neurons):\n    # 128 -> 64\n    conv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\")(input_layer)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = LeakyReLU(negative_slope=0.1)(conv1)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\")(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = LeakyReLU(negative_slope=0.1)(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n    pool1 = Dropout(0.25)(pool1)\n\n    # 64 -> 32\n    conv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\")(pool1)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = LeakyReLU(negative_slope=0.1)(conv2)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\")(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = LeakyReLU(negative_slope=0.1)(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n    pool2 = Dropout(0.5)(pool2)\n\n    # 32 -> 16\n    conv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\")(pool2)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = LeakyReLU(negative_slope=0.1)(conv3)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\")(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = LeakyReLU(negative_slope=0.1)(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n    pool3 = Dropout(0.5)(pool3)\n\n    # 16 -> 8\n    conv4 = Conv2D(start_neurons * 8, (3, 3), padding=\"same\")(pool3)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = LeakyReLU(negative_slope=0.1)(conv4)\n    conv4 = Conv2D(start_neurons * 8, (3, 3), padding=\"same\")(conv4)\n    conv4 = BatchNormalization()(conv4)\n    conv4 = LeakyReLU(negative_slope=0.1)(conv4)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n    pool4 = Dropout(0.5)(pool4)\n\n    # Middle\n    convm = Conv2D(start_neurons * 16, (3, 3), padding=\"same\")(pool4)\n    convm = BatchNormalization()(convm)\n    convm = LeakyReLU(negative_slope=0.1)(convm)\n    convm = Conv2D(start_neurons * 16, (3, 3), padding=\"same\")(convm)\n    convm = BatchNormalization()(convm)\n    convm = LeakyReLU(negative_slope=0.1)(convm)\n\n    # 8 -> 16\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = Dropout(0.5)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), padding=\"same\")(uconv4)\n    uconv4 = BatchNormalization()(uconv4)\n    uconv4 = LeakyReLU(negative_slope=0.1)(uconv4)\n    uconv4 = Conv2D(start_neurons * 8, (3, 3), padding=\"same\")(uconv4)\n    uconv4 = BatchNormalization()(uconv4)\n    uconv4 = LeakyReLU(negative_slope=0.1)(uconv4)\n\n    # 16 -> 32\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Dropout(0.5)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\")(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    uconv3 = LeakyReLU(negative_slope=0.1)(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\")(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    uconv3 = LeakyReLU(negative_slope=0.1)(uconv3)\n\n    # 32 -> 64\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Dropout(0.5)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\")(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = LeakyReLU(negative_slope=0.1)(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\")(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = LeakyReLU(negative_slope=0.1)(uconv2)\n\n    # 64 -> 128\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Dropout(0.5)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    uconv1 = LeakyReLU(negative_slope=0.1)(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\")(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    uconv1 = LeakyReLU(negative_slope=0.1)(uconv1)\n\n    uconv1 = Dropout(0.5)(uconv1)\n    output_layer = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n    \n    return output_layer\n\ninput_layer = Input((img_size_target, img_size_target, 1))\noutput_layer = build_model(input_layer, 16)\nmodel = Model(input_layer, output_layer)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:23.396811Z","iopub.execute_input":"2024-11-15T20:25:23.397192Z","iopub.status.idle":"2024-11-15T20:25:23.785696Z","shell.execute_reply.started":"2024-11-15T20:25:23.397137Z","shell.execute_reply":"2024-11-15T20:25:23.784704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model(input_layer, output_layer)\n\nmodel.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:23.786992Z","iopub.execute_input":"2024-11-15T20:25:23.787334Z","iopub.status.idle":"2024-11-15T20:25:23.923405Z","shell.execute_reply.started":"2024-11-15T20:25:23.787299Z","shell.execute_reply":"2024-11-15T20:25:23.922524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\nmodel_checkpoint = ModelCheckpoint(\"/kaggle/working/bestmodel.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-5, verbose=1)\n\nepochs = 200\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:23.928068Z","iopub.execute_input":"2024-11-15T20:25:23.928433Z","iopub.status.idle":"2024-11-15T20:25:23.934506Z","shell.execute_reply.started":"2024-11-15T20:25:23.928396Z","shell.execute_reply":"2024-11-15T20:25:23.933551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, y_train,\n                    validation_data=[x_valid, y_valid], \n                    epochs=epochs,\n                    batch_size=batch_size,\n                    callbacks=[early_stopping, model_checkpoint, reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:25:23.935826Z","iopub.execute_input":"2024-11-15T20:25:23.936182Z","iopub.status.idle":"2024-11-15T20:35:51.168666Z","shell.execute_reply.started":"2024-11-15T20:25:23.936150Z","shell.execute_reply":"2024-11-15T20:35:51.167798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:56:41.993313Z","iopub.execute_input":"2024-11-15T20:56:41.994169Z","iopub.status.idle":"2024-11-15T20:56:42.480579Z","shell.execute_reply.started":"2024-11-15T20:56:41.994122Z","shell.execute_reply":"2024-11-15T20:56:42.479616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = load_model(\"/kaggle/working/bestmodel.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T19:28:03.859100Z","iopub.execute_input":"2024-11-15T19:28:03.859495Z","iopub.status.idle":"2024-11-15T19:28:03.864037Z","shell.execute_reply.started":"2024-11-15T19:28:03.859455Z","shell.execute_reply":"2024-11-15T19:28:03.862941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Raw predict over val","metadata":{}},{"cell_type":"code","source":"preds_valid = model.predict(x_valid).reshape(-1, img_size_target, img_size_target)\npreds_valid = np.array([downsample(x) for x in preds_valid])\ny_valid_ori = np.array([train_df.loc[idx].masks for idx in ids_valid])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T20:56:55.263753Z","iopub.execute_input":"2024-11-15T20:56:55.264649Z","iopub.status.idle":"2024-11-15T20:56:57.884248Z","shell.execute_reply.started":"2024-11-15T20:56:55.264601Z","shell.execute_reply":"2024-11-15T20:56:57.883414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_images = 60\ngrid_width = 15\ngrid_height = int(max_images / grid_width)\nfig, axs = plt.subplots(grid_height * 2, grid_width, figsize=(grid_width, grid_height * 2))\nfor i, idx in enumerate(ids_valid[:max_images]):\n    img = train_df.loc[idx].images\n    mask = train_df.loc[idx].masks\n    pred = preds_valid[i]\n    \n    ax_img = axs[int(i / grid_width) * 2, i % grid_width]\n    ax_pred = axs[int(i / grid_width) * 2 + 1, i % grid_width]\n    \n    ax_img.imshow(img, cmap=\"Greys\")\n    ax_img.imshow(mask, alpha=0.3, cmap=\"Greens\")\n    ax_img.text(1, img_size_ori-1, train_df.loc[idx].z, color=\"black\")\n    ax_img.text(img_size_ori - 1, 1, round(train_df.loc[idx].coverage, 2), color=\"black\", ha=\"right\", va=\"top\")\n    ax_img.text(1, 1, train_df.loc[idx].coverage_class, color=\"black\", ha=\"left\", va=\"top\")\n    ax_img.set_yticklabels([])\n    ax_img.set_xticklabels([])\n    \n    ax_pred.imshow(pred, cmap=\"OrRd\")\n    ax_pred.set_yticklabels([])\n    ax_pred.set_xticklabels([])\n\nplt.suptitle(\"Top row: original images with masks, Bottom row: predicted masks. Top-left: coverage class, top-right: salt coverage, bottom-left: depth\")","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:00:47.660844Z","iopub.execute_input":"2024-11-15T21:00:47.661621Z","iopub.status.idle":"2024-11-15T21:00:59.153107Z","shell.execute_reply.started":"2024-11-15T21:00:47.661577Z","shell.execute_reply":"2024-11-15T21:00:59.151973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Raw predict over test","metadata":{}},{"cell_type":"code","source":"x_test = np.array([upsample(np.array(load_img(\"/kaggle/input/test/images/{}.png\".format(idx), color_mode='grayscale'))) / 255 for idx in tqdm(test_df.index)]).reshape(-1, img_size_target, img_size_target, 1)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:03:36.641688Z","iopub.execute_input":"2024-11-15T21:03:36.642458Z","iopub.status.idle":"2024-11-15T21:04:04.954648Z","shell.execute_reply.started":"2024-11-15T21:03:36.642412Z","shell.execute_reply":"2024-11-15T21:04:04.953703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_test_subset = x_test[0:32]\n\npreds_test_subset = model.predict(x_test_subset).reshape(-1, img_size_target, img_size_target)\npreds_test_subset = np.array([downsample(x) for x in preds_test_subset])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:09:23.320869Z","iopub.execute_input":"2024-11-15T21:09:23.321797Z","iopub.status.idle":"2024-11-15T21:09:23.443177Z","shell.execute_reply.started":"2024-11-15T21:09:23.321749Z","shell.execute_reply":"2024-11-15T21:09:23.442427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_width = 8\ngrid_height = int(np.ceil(len(x_test_subset) / grid_width))\n\nfig, axs = plt.subplots(grid_height * 2, grid_width, figsize=(grid_width, grid_height * 2))\n\nfor i in range(len(x_test_subset)):\n    img = x_test_subset[i].reshape(img_size_target, img_size_target)\n    pred = preds_test_subset[i]\n    \n    ax_img = axs[int(i / grid_width) * 2, i % grid_width]\n    ax_pred = axs[int(i / grid_width) * 2 + 1, i % grid_width]\n    \n    ax_img.imshow(img, cmap=\"Greys\")\n    ax_img.set_yticklabels([])\n    ax_img.set_xticklabels([])\n    \n    ax_pred.imshow(pred, cmap=\"OrRd\")\n    ax_pred.set_yticklabels([])\n    ax_pred.set_xticklabels([])\n\nplt.suptitle(\"Top row: original images, Bottom row: predicted masks\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:09:24.573084Z","iopub.execute_input":"2024-11-15T21:09:24.574035Z","iopub.status.idle":"2024-11-15T21:09:30.240196Z","shell.execute_reply.started":"2024-11-15T21:09:24.573992Z","shell.execute_reply":"2024-11-15T21:09:30.239217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Scoring","metadata":{}},{"cell_type":"code","source":"def iou_metric(y_true_in, y_pred_in, print_table=False):\n    labels = y_true_in\n    y_pred = y_pred_in\n    \n    true_objects = 2\n    pred_objects = 2\n\n    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n\n    # Compute areas (needed for finding the union between all objects)\n    area_true = np.histogram(labels, bins = true_objects)[0]\n    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n    area_true = np.expand_dims(area_true, -1)\n    area_pred = np.expand_dims(area_pred, 0)\n\n    # Compute union\n    union = area_true + area_pred - intersection\n\n    # Exclude background from the analysis\n    intersection = intersection[1:,1:]\n    union = union[1:,1:]\n    union[union == 0] = 1e-9\n\n    # Compute the intersection over union\n    iou = intersection / union\n\n    # Precision helper function\n    def precision_at(threshold, iou):\n        matches = iou > threshold\n        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n        return tp, fp, fn\n\n    # Loop over IoU thresholds\n    prec = []\n    if print_table:\n        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n    for t in np.arange(0.5, 1.0, 0.05):\n        tp, fp, fn = precision_at(t, iou)\n        if (tp + fp + fn) > 0:\n            p = tp / (tp + fp + fn)\n        else:\n            p = 0\n        if print_table:\n            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n        prec.append(p)\n    \n    if print_table:\n        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n    return np.mean(prec)\n\ndef iou_metric_batch(y_true_in, y_pred_in):\n    batch_size = y_true_in.shape[0]\n    metric = []\n    for batch in range(batch_size):\n        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n        metric.append(value)\n    return np.mean(metric)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:09:39.656669Z","iopub.execute_input":"2024-11-15T21:09:39.657404Z","iopub.status.idle":"2024-11-15T21:09:39.671945Z","shell.execute_reply.started":"2024-11-15T21:09:39.657361Z","shell.execute_reply":"2024-11-15T21:09:39.671012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds = np.linspace(0, 1, 50)\nious = np.array([iou_metric_batch(y_valid_ori, np.int32(preds_valid > threshold)) for threshold in tqdm(thresholds)])","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:09:47.669826Z","iopub.execute_input":"2024-11-15T21:09:47.670753Z","iopub.status.idle":"2024-11-15T21:10:53.169363Z","shell.execute_reply.started":"2024-11-15T21:09:47.670704Z","shell.execute_reply":"2024-11-15T21:10:53.168306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_best_index = np.argmax(ious[9:-10]) + 9\niou_best = ious[threshold_best_index]\nthreshold_best = thresholds[threshold_best_index]","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:10:53.171106Z","iopub.execute_input":"2024-11-15T21:10:53.171444Z","iopub.status.idle":"2024-11-15T21:10:53.176465Z","shell.execute_reply.started":"2024-11-15T21:10:53.171409Z","shell.execute_reply":"2024-11-15T21:10:53.175407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(thresholds, ious)\nplt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\nplt.xlabel(\"Threshold\")\nplt.ylabel(\"IoU\")\nplt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:10:53.177867Z","iopub.execute_input":"2024-11-15T21:10:53.178220Z","iopub.status.idle":"2024-11-15T21:10:53.527810Z","shell.execute_reply.started":"2024-11-15T21:10:53.178181Z","shell.execute_reply":"2024-11-15T21:10:53.526846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n\n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:10:53.529734Z","iopub.execute_input":"2024-11-15T21:10:53.530046Z","iopub.status.idle":"2024-11-15T21:10:53.538313Z","shell.execute_reply.started":"2024-11-15T21:10:53.530012Z","shell.execute_reply":"2024-11-15T21:10:53.537283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_test = model.predict(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:10:53.539276Z","iopub.execute_input":"2024-11-15T21:10:53.539601Z","iopub.status.idle":"2024-11-15T21:11:10.041561Z","shell.execute_reply.started":"2024-11-15T21:10:53.539569Z","shell.execute_reply":"2024-11-15T21:11:10.040674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_dict = {idx: RLenc(np.round(downsample(preds_test[i]) > threshold_best)) for i, idx in enumerate(tqdm(test_df.index.values))}","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:11:10.042928Z","iopub.execute_input":"2024-11-15T21:11:10.043689Z","iopub.status.idle":"2024-11-15T21:21:42.024045Z","shell.execute_reply.started":"2024-11-15T21:11:10.043639Z","shell.execute_reply":"2024-11-15T21:21:42.023050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-11-15T21:21:42.025327Z","iopub.execute_input":"2024-11-15T21:21:42.025664Z","iopub.status.idle":"2024-11-15T21:21:42.249649Z","shell.execute_reply.started":"2024-11-15T21:21:42.025598Z","shell.execute_reply":"2024-11-15T21:21:42.248614Z"},"trusted":true},"execution_count":null,"outputs":[]}]}